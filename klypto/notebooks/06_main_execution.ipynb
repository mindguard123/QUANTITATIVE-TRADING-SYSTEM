{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d86634d6",
   "metadata": {},
   "source": [
    "# Complete Quantitative Trading System - Main Execution\n",
    "\n",
    "This notebook executes the complete quantitative trading pipeline from data acquisition to backtesting.\n",
    "\n",
    "**Pipeline:**\n",
    "1. Data Acquisition\n",
    "2. Feature Engineering (EMA + Technical Indicators)\n",
    "3. Outlier Detection and Handling\n",
    "4. HMM Regime Detection\n",
    "5. ML Model Training (XGBoost, LightGBM, Neural Networks)\n",
    "6. Signal Generation\n",
    "7. Backtesting\n",
    "8. Performance Analysis\n",
    "\n",
    "**Author:** Senior Quantitative Researcher  \n",
    "**Date:** January 2026  \n",
    "**Market:** Indian Equity Markets (NIFTY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969924a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom modules\n",
    "from src.data_acquisition import DataAcquisition\n",
    "from src.feature_engineering import FeatureEngineer\n",
    "from src.outlier_detection import OutlierDetector\n",
    "from src.hmm_regime import HMMRegimeDetector\n",
    "from src.ml_models import MLModelTrainer\n",
    "from src.backtesting import BacktestEngine\n",
    "from src.visualization import Visualizer\n",
    "from src.utils import (\n",
    "    load_config, setup_logging, split_train_test_by_date,\n",
    "    save_dataframe, load_dataframe\n",
    ")\n",
    "\n",
    "# Setup\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "logger = setup_logging(log_level='INFO')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"QUANTITATIVE TRADING SYSTEM\")\n",
    "print(\"Production-Grade Implementation for Indian Markets\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nAll modules loaded successfully!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61af1442",
   "metadata": {},
   "source": [
    "## 1. Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dce3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = load_config('../configs/config.yaml')\n",
    "\n",
    "# Extract parameters\n",
    "SYMBOL = config['data']['symbol']\n",
    "START_DATE = config['data']['start_date']\n",
    "END_DATE = config['data']['end_date']\n",
    "INITIAL_CAPITAL = config['backtesting']['initial_capital']\n",
    "\n",
    "print(f\"Configuration Loaded:\")\n",
    "print(f\"  Symbol: {SYMBOL}\")\n",
    "print(f\"  Period: {START_DATE} to {END_DATE}\")\n",
    "print(f\"  Initial Capital: ‚Çπ{INITIAL_CAPITAL:,.0f}\")\n",
    "print(f\"  HMM States: {config['hmm']['n_states']}\")\n",
    "print(f\"  Strategy: {config['strategy']['method']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eab0446",
   "metadata": {},
   "source": [
    "## 2. Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205cc01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 1: DATA ACQUISITION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize data acquisition\n",
    "da = DataAcquisition(\n",
    "    symbol=SYMBOL,\n",
    "    start_date=START_DATE,\n",
    "    end_date=END_DATE,\n",
    "    source=config['data']['source']\n",
    ")\n",
    "\n",
    "# Fetch data\n",
    "df_raw = da.fetch_data()\n",
    "\n",
    "print(f\"\\nData Shape: {df_raw.shape}\")\n",
    "print(f\"Date Range: {df_raw.index[0].date()} to {df_raw.index[-1].date()}\")\n",
    "print(f\"\\nColumns: {list(df_raw.columns)}\")\n",
    "\n",
    "# Save raw data\n",
    "save_dataframe(df_raw, '../data/raw/nifty_raw.csv')\n",
    "print(\"\\n‚úì Raw data saved\")\n",
    "\n",
    "df_raw.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06c553b",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aeae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 2: FEATURE ENGINEERING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize feature engineer\n",
    "fe = FeatureEngineer(df_raw)\n",
    "\n",
    "# Create all features\n",
    "df_features = fe.create_all_features(\n",
    "    ema_periods=config['features']['ema_periods'],\n",
    "    add_lagged=True\n",
    ")\n",
    "\n",
    "print(f\"\\nFeature Engineering Complete!\")\n",
    "print(f\"Original columns: {len(df_raw.columns)}\")\n",
    "print(f\"Total features: {len(df_features.columns)}\")\n",
    "print(f\"Data shape: {df_features.shape}\")\n",
    "\n",
    "# Display feature categories\n",
    "print(f\"\\nFeature Categories:\")\n",
    "print(f\"  EMA features: {len(fe.get_feature_names('ema'))}\")\n",
    "print(f\"  Momentum indicators: {len(fe.get_feature_names('momentum'))}\")\n",
    "print(f\"  Volatility indicators: {len(fe.get_feature_names('volatility'))}\")\n",
    "print(f\"  Volume features: {len(fe.get_feature_names('volume'))}\")\n",
    "print(f\"  Price features: {len(fe.get_feature_names('price'))}\")\n",
    "\n",
    "# Save features\n",
    "save_dataframe(df_features, '../data/processed/nifty_features.csv')\n",
    "print(\"\\n‚úì Features saved\")\n",
    "\n",
    "df_features.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15738949",
   "metadata": {},
   "source": [
    "## 4. Outlier Detection and Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64914bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 3: OUTLIER DETECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize outlier detector\n",
    "outlier_detector = OutlierDetector(df_features)\n",
    "\n",
    "# Detect all outliers\n",
    "outliers = outlier_detector.detect_all()\n",
    "\n",
    "# Display summary\n",
    "print(\"\\nOutlier Detection Summary:\")\n",
    "print(outlier_detector.get_summary())\n",
    "\n",
    "# Handle outliers\n",
    "df_clean = outlier_detector.handle_outliers(\n",
    "    method=config['outliers']['handling']['method'],\n",
    "    columns=['returns', 'volume'],\n",
    "    percentile=tuple(config['outliers']['handling']['percentile'])\n",
    ")\n",
    "\n",
    "print(f\"\\nData shape after outlier handling: {df_clean.shape}\")\n",
    "\n",
    "# Save cleaned data\n",
    "save_dataframe(df_clean, '../data/processed/nifty_clean.csv')\n",
    "print(\"‚úì Cleaned data saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efe030f",
   "metadata": {},
   "source": [
    "## 5. HMM Regime Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fb90d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 4: HMM REGIME DETECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize HMM\n",
    "hmm_detector = HMMRegimeDetector(\n",
    "    n_states=config['hmm']['n_states'],\n",
    "    n_iter=config['hmm']['n_iter'],\n",
    "    random_state=config['hmm']['random_state']\n",
    ")\n",
    "\n",
    "# Fit and predict regimes\n",
    "df_with_regime = hmm_detector.fit_predict(\n",
    "    df_clean,\n",
    "    feature_columns=config['hmm']['features']\n",
    ")\n",
    "\n",
    "print(\"\\nRegime Detection Complete!\")\n",
    "print(f\"\\nRegime Distribution:\")\n",
    "print(df_with_regime['regime_label'].value_counts())\n",
    "\n",
    "# Analyze transitions\n",
    "print(\"\\nRegime Transition Matrix:\")\n",
    "transitions = hmm_detector.get_regime_transitions(df_with_regime)\n",
    "print(transitions)\n",
    "\n",
    "# Current regime\n",
    "current_regime = hmm_detector.get_current_regime(df_with_regime)\n",
    "print(f\"\\nCurrent Market Regime: {current_regime['regime_label']}\")\n",
    "\n",
    "# Save model and data\n",
    "hmm_detector.save('../models/hmm_regime_model.pkl')\n",
    "save_dataframe(df_with_regime, '../data/processed/nifty_with_regime.csv')\n",
    "print(\"\\n‚úì HMM model and data saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da2f0da",
   "metadata": {},
   "source": [
    "## 6. Prepare ML Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32ec652",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 5: ML DATA PREPARATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create target variable\n",
    "ml_trainer = MLModelTrainer(\n",
    "    model_type='xgboost',\n",
    "    task='classification',\n",
    "    random_state=config['execution']['random_state']\n",
    ")\n",
    "\n",
    "df_ml = ml_trainer.create_target(\n",
    "    df_with_regime,\n",
    "    method=config['ml_models']['target']['method'],\n",
    "    horizon=config['ml_models']['target']['horizon']\n",
    ")\n",
    "\n",
    "print(f\"ML data shape: {df_ml.shape}\")\n",
    "\n",
    "# Split data\n",
    "train_df, val_df, test_df = split_train_test_by_date(\n",
    "    df_ml,\n",
    "    train_ratio=config['ml_models']['train_ratio'],\n",
    "    validation_ratio=config['ml_models']['validation_ratio']\n",
    ")\n",
    "\n",
    "print(f\"\\nData Split:\")\n",
    "print(f\"  Training: {len(train_df)} samples ({train_df.index[0].date()} to {train_df.index[-1].date()})\")\n",
    "print(f\"  Validation: {len(val_df)} samples ({val_df.index[0].date()} to {val_df.index[-1].date()})\")\n",
    "print(f\"  Test: {len(test_df)} samples ({test_df.index[0].date()} to {test_df.index[-1].date()})\")\n",
    "\n",
    "# Prepare features and target\n",
    "X_train, y_train = ml_trainer.prepare_data(train_df, 'target')\n",
    "X_val, y_val = ml_trainer.prepare_data(val_df, 'target')\n",
    "X_test, y_test = ml_trainer.prepare_data(test_df, 'target')\n",
    "\n",
    "print(f\"\\nFeature shape: {X_train.shape}\")\n",
    "print(f\"Number of features: {len(ml_trainer.feature_columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4792e57",
   "metadata": {},
   "source": [
    "## 7. Train ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a65954",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 6: ML MODEL TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train XGBoost\n",
    "print(\"\\nTraining XGBoost...\")\n",
    "xgb_trainer = MLModelTrainer('xgboost', 'classification', random_state=42)\n",
    "xgb_trainer.feature_columns = ml_trainer.feature_columns\n",
    "xgb_metrics = xgb_trainer.train(\n",
    "    X_train, y_train, X_val, y_val,\n",
    "    hyperparameters=config['ml_models']['xgboost']\n",
    ")\n",
    "print(f\"XGBoost Metrics: {xgb_metrics}\")\n",
    "xgb_trainer.save('../models/xgboost_model.pkl')\n",
    "\n",
    "# Train LightGBM\n",
    "print(\"\\nTraining LightGBM...\")\n",
    "lgb_trainer = MLModelTrainer('lightgbm', 'classification', random_state=42)\n",
    "lgb_trainer.feature_columns = ml_trainer.feature_columns\n",
    "lgb_metrics = lgb_trainer.train(\n",
    "    X_train, y_train, X_val, y_val,\n",
    "    hyperparameters=config['ml_models']['lightgbm']\n",
    ")\n",
    "print(f\"LightGBM Metrics: {lgb_metrics}\")\n",
    "lgb_trainer.save('../models/lightgbm_model.pkl')\n",
    "\n",
    "# Train Neural Network\n",
    "print(\"\\nTraining Neural Network...\")\n",
    "nn_trainer = MLModelTrainer('neural_network', 'classification', random_state=42)\n",
    "nn_trainer.feature_columns = ml_trainer.feature_columns\n",
    "nn_metrics = nn_trainer.train(\n",
    "    X_train, y_train, X_val, y_val,\n",
    "    hyperparameters=config['ml_models']['neural_network']\n",
    ")\n",
    "print(f\"Neural Network Metrics: {nn_metrics}\")\n",
    "nn_trainer.save('../models/nn_model.pkl')\n",
    "\n",
    "# Compare models\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['XGBoost', 'LightGBM', 'Neural Network'],\n",
    "    'Accuracy': [xgb_metrics['accuracy'], lgb_metrics['accuracy'], nn_metrics['accuracy']],\n",
    "    'Precision': [xgb_metrics['precision'], lgb_metrics['precision'], nn_metrics['precision']],\n",
    "    'Recall': [xgb_metrics['recall'], lgb_metrics['recall'], nn_metrics['recall']],\n",
    "    'F1-Score': [xgb_metrics['f1'], lgb_metrics['f1'], nn_metrics['f1']],\n",
    "    'Val_Accuracy': [xgb_metrics['val_accuracy'], lgb_metrics['val_accuracy'], nn_metrics['val_accuracy']]\n",
    "})\n",
    "print(comparison)\n",
    "\n",
    "# Feature importance (XGBoost)\n",
    "print(\"\\nTop 10 Important Features (XGBoost):\")\n",
    "print(xgb_trainer.get_feature_importance(top_n=10))\n",
    "\n",
    "print(\"\\n‚úì All models trained and saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64362c97",
   "metadata": {},
   "source": [
    "## 8. Generate Trading Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db2c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 7: SIGNAL GENERATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Generate predictions for test set\n",
    "xgb_pred = xgb_trainer.predict_proba(X_test)\n",
    "lgb_pred = lgb_trainer.predict_proba(X_test)\n",
    "nn_pred = nn_trainer.predict_proba(X_test)\n",
    "\n",
    "# Ensemble predictions (weighted average)\n",
    "weights = config['ml_models']['ensemble']['weights']\n",
    "ensemble_pred = (\n",
    "    weights['xgboost'] * xgb_pred +\n",
    "    weights['lightgbm'] * lgb_pred +\n",
    "    weights['neural_network'] * nn_pred\n",
    ")\n",
    "\n",
    "# Create signals based on probability threshold\n",
    "threshold = config['strategy']['thresholds']['ml_probability']\n",
    "signals = pd.Series(0, index=test_df.index)\n",
    "signals[ensemble_pred > threshold] = 1  # Buy\n",
    "signals[ensemble_pred < (1 - threshold)] = -1  # Sell\n",
    "\n",
    "print(f\"\\nSignal Distribution:\")\n",
    "print(f\"  Buy signals: {(signals == 1).sum()}\")\n",
    "print(f\"  Sell signals: {(signals == -1).sum()}\")\n",
    "print(f\"  Hold signals: {(signals == 0).sum()}\")\n",
    "\n",
    "# Apply regime filter if configured\n",
    "if config['strategy']['use_regime_filter']:\n",
    "    allowed_regimes = config['strategy']['trade_regimes']\n",
    "    regime_mask = test_df['regime_label'].isin(allowed_regimes)\n",
    "    signals[~regime_mask] = 0\n",
    "    print(f\"\\nAfter regime filter:\")\n",
    "    print(f\"  Buy signals: {(signals == 1).sum()}\")\n",
    "    print(f\"  Sell signals: {(signals == -1).sum()}\")\n",
    "    print(f\"  Hold signals: {(signals == 0).sum()}\")\n",
    "\n",
    "# Save signals\n",
    "signals_df = pd.DataFrame({\n",
    "    'signal': signals,\n",
    "    'xgb_prob': xgb_pred,\n",
    "    'lgb_prob': lgb_pred,\n",
    "    'nn_prob': nn_pred,\n",
    "    'ensemble_prob': ensemble_pred\n",
    "}, index=test_df.index)\n",
    "save_dataframe(signals_df, '../results/trading_signals.csv')\n",
    "print(\"\\n‚úì Signals saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec892948",
   "metadata": {},
   "source": [
    "## 9. Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7586898",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 8: BACKTESTING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize backtest engine\n",
    "backtest_engine = BacktestEngine(\n",
    "    initial_capital=config['backtesting']['initial_capital'],\n",
    "    transaction_cost=config['backtesting']['transaction_cost'],\n",
    "    slippage=config['backtesting']['slippage'],\n",
    "    position_size=config['backtesting']['position_size']\n",
    ")\n",
    "\n",
    "# Run backtest\n",
    "backtest_results = backtest_engine.run_backtest(\n",
    "    test_df,\n",
    "    signals,\n",
    "    price_column='close'\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "backtest_engine.print_summary()\n",
    "\n",
    "# Save results\n",
    "save_dataframe(backtest_results['equity_curve'], '../results/equity_curve.csv')\n",
    "save_dataframe(backtest_results['trades'], '../results/trade_log.csv')\n",
    "\n",
    "# Save metrics\n",
    "metrics_df = pd.DataFrame([backtest_results['metrics']])\n",
    "save_dataframe(metrics_df, '../results/backtest_metrics.csv')\n",
    "\n",
    "print(\"\\n‚úì Backtest results saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56de7e17",
   "metadata": {},
   "source": [
    "## 10. Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d074d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 9: VISUALIZATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize visualizer\n",
    "viz = Visualizer(output_dir='../plots')\n",
    "\n",
    "# Create comprehensive report\n",
    "viz.create_backtest_report(\n",
    "    backtest_results,\n",
    "    test_df,\n",
    "    prefix='final_backtest'\n",
    ")\n",
    "\n",
    "# Additional visualizations\n",
    "viz.plot_regime_analysis(\n",
    "    df_with_regime,\n",
    "    title='HMM Market Regime Analysis',\n",
    "    filename='regime_analysis.png'\n",
    ")\n",
    "\n",
    "viz.plot_feature_importance(\n",
    "    xgb_trainer.get_feature_importance(top_n=15),\n",
    "    top_n=15,\n",
    "    title='Top 15 Features (XGBoost)',\n",
    "    filename='feature_importance.png'\n",
    ")\n",
    "\n",
    "viz.plot_ema_analysis(\n",
    "    df_features.iloc[-252:],  # Last year\n",
    "    ema_periods=[20, 50, 200],\n",
    "    title='EMA Analysis (Last Year)',\n",
    "    filename='ema_analysis.png'\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì All visualizations created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30760b24",
   "metadata": {},
   "source": [
    "## 11. Final Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d2d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" \" * 15 + \"QUANTITATIVE TRADING SYSTEM\")\n",
    "print(\" \" * 20 + \"FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìä DATA\")\n",
    "print(f\"  Symbol: {SYMBOL}\")\n",
    "print(f\"  Period: {START_DATE} to {END_DATE}\")\n",
    "print(f\"  Total Days: {len(df_raw)}\")\n",
    "print(f\"  Features Created: {len(df_features.columns)}\")\n",
    "\n",
    "print(f\"\\nüîç REGIME DETECTION\")\n",
    "print(f\"  States: {config['hmm']['n_states']}\")\n",
    "print(f\"  Current Regime: {current_regime['regime_label']}\")\n",
    "\n",
    "print(f\"\\nü§ñ MACHINE LEARNING\")\n",
    "print(f\"  Models Trained: XGBoost, LightGBM, Neural Network\")\n",
    "print(f\"  Best Model Accuracy: {max(xgb_metrics['val_accuracy'], lgb_metrics['val_accuracy'], nn_metrics['val_accuracy']):.2%}\")\n",
    "\n",
    "print(f\"\\nüìà BACKTESTING PERFORMANCE\")\n",
    "metrics = backtest_results['metrics']\n",
    "print(f\"  Initial Capital: ‚Çπ{metrics['initial_capital']:,.0f}\")\n",
    "print(f\"  Final Value: ‚Çπ{metrics['final_value']:,.0f}\")\n",
    "print(f\"  Total Return: {metrics['total_return_pct']:.2f}%\")\n",
    "print(f\"  Annualized Return: {metrics['annualized_return_pct']:.2f}%\")\n",
    "print(f\"  Sharpe Ratio: {metrics['sharpe_ratio']:.2f}\")\n",
    "print(f\"  Max Drawdown: {metrics['max_drawdown_pct']:.2f}%\")\n",
    "print(f\"  Win Rate: {metrics.get('win_rate_pct', 0):.2f}%\")\n",
    "print(f\"  Total Trades: {metrics.get('total_trades', 0):.0f}\")\n",
    "\n",
    "print(f\"\\nüí∞ COMPARISON\")\n",
    "print(f\"  Buy & Hold Return: {metrics['buy_hold_return_pct']:.2f}%\")\n",
    "print(f\"  Strategy Excess Return: {metrics['excess_return_pct']:.2f}%\")\n",
    "\n",
    "outperformance = \"‚úì\" if metrics['excess_return'] > 0 else \"‚úó\"\n",
    "print(f\"\\n{outperformance} Strategy {'OUTPERFORMED' if metrics['excess_return'] > 0 else 'UNDERPERFORMED'} Buy & Hold\")\n",
    "\n",
    "print(f\"\\nüìÅ OUTPUT FILES\")\n",
    "print(f\"  Data: data/processed/\")\n",
    "print(f\"  Models: models/\")\n",
    "print(f\"  Plots: plots/\")\n",
    "print(f\"  Results: results/\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" \" * 22 + \"EXECUTION COMPLETE\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "print(\"‚úì All steps completed successfully!\")\n",
    "print(\"‚úì System ready for production deployment\")\n",
    "print(\"\\n‚ö†Ô∏è  DISCLAIMER: Past performance does not guarantee future results.\")\n",
    "print(\"    Always perform thorough testing before live trading.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
